checkpoints and models will be saved at: _checkpoints
Logging to _checkpoints
creating model and diffusion...
creating data loader...
training...
loading model from checkpoint: _checkpoints/model000100.pt...
loading optimizer state from checkpoint: _checkpoints/opt000100.pt
loading EMA from checkpoint: _checkpoints/ema_0.9999_000100.pt...
checkpoints and models will be saved at: _checkpoints
checkpoints and models will be saved at: _checkpoints
checkpoints and models will be saved at: _checkpoints
------------------------
| grad_norm | 0.134    |
| loss      | 0.0102   |
| loss_q0   | 0.029    |
| loss_q1   | 0.0139   |
| loss_q2   | 0.00465  |
| loss_q3   | 0.00246  |
| mse       | 0.0102   |
| mse_q0    | 0.029    |
| mse_q1    | 0.0139   |
| mse_q2    | 0.00465  |
| mse_q3    | 0.00246  |
| samples   | 1.29e+04 |
| step      | 100      |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.166    |
| loss      | 0.0257   |
| loss_q0   | 0.0741   |
| loss_q1   | 0.0127   |
| loss_q2   | 0.00394  |
| loss_q3   | 0.00304  |
| mse       | 0.0257   |
| mse_q0    | 0.0741   |
| mse_q1    | 0.0127   |
| mse_q2    | 0.00394  |
| mse_q3    | 0.00304  |
| samples   | 1.42e+04 |
| step      | 110      |
------------------------
------------------------
| grad_norm | 0.186    |
| loss      | 0.0237   |
| loss_q0   | 0.0796   |
| loss_q1   | 0.0111   |
| loss_q2   | 0.00387  |
| loss_q3   | 0.00261  |
| mse       | 0.0237   |
| mse_q0    | 0.0796   |
| mse_q1    | 0.0111   |
| mse_q2    | 0.00387  |
| mse_q3    | 0.00261  |
| samples   | 1.55e+04 |
| step      | 120      |
------------------------
------------------------
| grad_norm | 0.178    |
| loss      | 0.0224   |
| loss_q0   | 0.0786   |
| loss_q1   | 0.0117   |
| loss_q2   | 0.00397  |
| loss_q3   | 0.0027   |
| mse       | 0.0224   |
| mse_q0    | 0.0786   |
| mse_q1    | 0.0117   |
| mse_q2    | 0.00397  |
| mse_q3    | 0.0027   |
| samples   | 1.68e+04 |
| step      | 130      |
------------------------
------------------------
| grad_norm | 0.264    |
| loss      | 0.0239   |
| loss_q0   | 0.0863   |
| loss_q1   | 0.011    |
| loss_q2   | 0.00354  |
| loss_q3   | 0.00256  |
| mse       | 0.0239   |
| mse_q0    | 0.0863   |
| mse_q1    | 0.011    |
| mse_q2    | 0.00354  |
| mse_q3    | 0.00256  |
| samples   | 1.8e+04  |
| step      | 140      |
------------------------
------------------------
| grad_norm | 0.238    |
| loss      | 0.0332   |
| loss_q0   | 0.112    |
| loss_q1   | 0.0113   |
| loss_q2   | 0.00357  |
| loss_q3   | 0.00243  |
| mse       | 0.0332   |
| mse_q0    | 0.112    |
| mse_q1    | 0.0113   |
| mse_q2    | 0.00357  |
| mse_q3    | 0.00243  |
| samples   | 1.93e+04 |
| step      | 150      |
------------------------
------------------------
| grad_norm | 0.215    |
| loss      | 0.035    |
| loss_q0   | 0.103    |
| loss_q1   | 0.0121   |
| loss_q2   | 0.00385  |
| loss_q3   | 0.00264  |
| mse       | 0.035    |
| mse_q0    | 0.103    |
| mse_q1    | 0.0121   |
| mse_q2    | 0.00385  |
| mse_q3    | 0.00264  |
| samples   | 2.06e+04 |
| step      | 160      |
------------------------
------------------------
| grad_norm | 0.202    |
| loss      | 0.031    |
| loss_q0   | 0.102    |
| loss_q1   | 0.0109   |
| loss_q2   | 0.0037   |
| loss_q3   | 0.0021   |
| mse       | 0.031    |
| mse_q0    | 0.102    |
| mse_q1    | 0.0109   |
| mse_q2    | 0.0037   |
| mse_q3    | 0.0021   |
| samples   | 2.19e+04 |
| step      | 170      |
------------------------
------------------------
| grad_norm | 0.145    |
| loss      | 0.0234   |
| loss_q0   | 0.0875   |
| loss_q1   | 0.0114   |
| loss_q2   | 0.00345  |
| loss_q3   | 0.00198  |
| mse       | 0.0234   |
| mse_q0    | 0.0875   |
| mse_q1    | 0.0114   |
| mse_q2    | 0.00345  |
| mse_q3    | 0.00198  |
| samples   | 2.32e+04 |
| step      | 180      |
------------------------
------------------------
| grad_norm | 0.145    |
| loss      | 0.0327   |
| loss_q0   | 0.104    |
| loss_q1   | 0.0108   |
| loss_q2   | 0.00308  |
| loss_q3   | 0.00202  |
| mse       | 0.0327   |
| mse_q0    | 0.104    |
| mse_q1    | 0.0108   |
| mse_q2    | 0.00308  |
| mse_q3    | 0.00202  |
| samples   | 2.44e+04 |
| step      | 190      |
------------------------
------------------------
| grad_norm | 0.195    |
| loss      | 0.0248   |
| loss_q0   | 0.0867   |
| loss_q1   | 0.00962  |
| loss_q2   | 0.00313  |
| loss_q3   | 0.00221  |
| mse       | 0.0248   |
| mse_q0    | 0.0867   |
| mse_q1    | 0.00962  |
| mse_q2    | 0.00313  |
| mse_q3    | 0.00221  |
| samples   | 2.57e+04 |
| step      | 200      |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.132    |
| loss      | 0.0274   |
| loss_q0   | 0.0914   |
| loss_q1   | 0.0106   |
| loss_q2   | 0.00344  |
| loss_q3   | 0.00191  |
| mse       | 0.0274   |
| mse_q0    | 0.0914   |
| mse_q1    | 0.0106   |
| mse_q2    | 0.00344  |
| mse_q3    | 0.00191  |
| samples   | 2.7e+04  |
| step      | 210      |
------------------------
------------------------
| grad_norm | 0.165    |
| loss      | 0.0248   |
| loss_q0   | 0.0759   |
| loss_q1   | 0.0096   |
| loss_q2   | 0.0032   |
| loss_q3   | 0.00187  |
| mse       | 0.0248   |
| mse_q0    | 0.0759   |
| mse_q1    | 0.0096   |
| mse_q2    | 0.0032   |
| mse_q3    | 0.00187  |
| samples   | 2.83e+04 |
| step      | 220      |
------------------------
------------------------
| grad_norm | 0.139    |
| loss      | 0.0191   |
| loss_q0   | 0.0704   |
| loss_q1   | 0.0104   |
| loss_q2   | 0.00325  |
| loss_q3   | 0.00178  |
| mse       | 0.0191   |
| mse_q0    | 0.0704   |
| mse_q1    | 0.0104   |
| mse_q2    | 0.00325  |
| mse_q3    | 0.00178  |
| samples   | 2.96e+04 |
| step      | 230      |
------------------------
------------------------
| grad_norm | 0.169    |
| loss      | 0.0291   |
| loss_q0   | 0.104    |
| loss_q1   | 0.0113   |
| loss_q2   | 0.00317  |
| loss_q3   | 0.00198  |
| mse       | 0.0291   |
| mse_q0    | 0.104    |
| mse_q1    | 0.0113   |
| mse_q2    | 0.00317  |
| mse_q3    | 0.00198  |
| samples   | 3.08e+04 |
| step      | 240      |
------------------------
------------------------
| grad_norm | 0.233    |
| loss      | 0.0244   |
| loss_q0   | 0.0923   |
| loss_q1   | 0.0108   |
| loss_q2   | 0.00326  |
| loss_q3   | 0.00187  |
| mse       | 0.0244   |
| mse_q0    | 0.0923   |
| mse_q1    | 0.0108   |
| mse_q2    | 0.00326  |
| mse_q3    | 0.00187  |
| samples   | 3.21e+04 |
| step      | 250      |
------------------------
------------------------
| grad_norm | 0.129    |
| loss      | 0.0201   |
| loss_q0   | 0.068    |
| loss_q1   | 0.0106   |
| loss_q2   | 0.00264  |
| loss_q3   | 0.00159  |
| mse       | 0.0201   |
| mse_q0    | 0.068    |
| mse_q1    | 0.0106   |
| mse_q2    | 0.00264  |
| mse_q3    | 0.00159  |
| samples   | 3.34e+04 |
| step      | 260      |
------------------------
------------------------
| grad_norm | 0.132    |
| loss      | 0.0226   |
| loss_q0   | 0.0873   |
| loss_q1   | 0.00963  |
| loss_q2   | 0.00265  |
| loss_q3   | 0.00171  |
| mse       | 0.0226   |
| mse_q0    | 0.0873   |
| mse_q1    | 0.00963  |
| mse_q2    | 0.00265  |
| mse_q3    | 0.00171  |
| samples   | 3.47e+04 |
| step      | 270      |
------------------------
------------------------
| grad_norm | 0.126    |
| loss      | 0.0237   |
| loss_q0   | 0.0751   |
| loss_q1   | 0.0106   |
| loss_q2   | 0.00265  |
| loss_q3   | 0.00172  |
| mse       | 0.0237   |
| mse_q0    | 0.0751   |
| mse_q1    | 0.0106   |
| mse_q2    | 0.00265  |
| mse_q3    | 0.00172  |
| samples   | 3.6e+04  |
| step      | 280      |
------------------------
------------------------
| grad_norm | 0.157    |
| loss      | 0.0246   |
| loss_q0   | 0.0814   |
| loss_q1   | 0.0107   |
| loss_q2   | 0.00273  |
| loss_q3   | 0.00154  |
| mse       | 0.0246   |
| mse_q0    | 0.0814   |
| mse_q1    | 0.0107   |
| mse_q2    | 0.00273  |
| mse_q3    | 0.00154  |
| samples   | 3.72e+04 |
| step      | 290      |
------------------------
------------------------
| grad_norm | 0.21     |
| loss      | 0.021    |
| loss_q0   | 0.0705   |
| loss_q1   | 0.0106   |
| loss_q2   | 0.00327  |
| loss_q3   | 0.00187  |
| mse       | 0.021    |
| mse_q0    | 0.0705   |
| mse_q1    | 0.0106   |
| mse_q2    | 0.00327  |
| mse_q3    | 0.00187  |
| samples   | 3.85e+04 |
| step      | 300      |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.141    |
| loss      | 0.0193   |
| loss_q0   | 0.0636   |
| loss_q1   | 0.0114   |
| loss_q2   | 0.00281  |
| loss_q3   | 0.0015   |
| mse       | 0.0193   |
| mse_q0    | 0.0636   |
| mse_q1    | 0.0114   |
| mse_q2    | 0.00281  |
| mse_q3    | 0.0015   |
| samples   | 3.98e+04 |
| step      | 310      |
------------------------
------------------------
| grad_norm | 0.125    |
| loss      | 0.0274   |
| loss_q0   | 0.0858   |
| loss_q1   | 0.00996  |
| loss_q2   | 0.00263  |
| loss_q3   | 0.00168  |
| mse       | 0.0274   |
| mse_q0    | 0.0858   |
| mse_q1    | 0.00996  |
| mse_q2    | 0.00263  |
| mse_q3    | 0.00168  |
| samples   | 4.11e+04 |
| step      | 320      |
------------------------
------------------------
| grad_norm | 0.116    |
| loss      | 0.0259   |
| loss_q0   | 0.0836   |
| loss_q1   | 0.00951  |
| loss_q2   | 0.00242  |
| loss_q3   | 0.00141  |
| mse       | 0.0259   |
| mse_q0    | 0.0836   |
| mse_q1    | 0.00951  |
| mse_q2    | 0.00242  |
| mse_q3    | 0.00141  |
| samples   | 4.24e+04 |
| step      | 330      |
------------------------
------------------------
| grad_norm | 0.138    |
| loss      | 0.0282   |
| loss_q0   | 0.0939   |
| loss_q1   | 0.00986  |
| loss_q2   | 0.00266  |
| loss_q3   | 0.00134  |
| mse       | 0.0282   |
| mse_q0    | 0.0939   |
| mse_q1    | 0.00986  |
| mse_q2    | 0.00266  |
| mse_q3    | 0.00134  |
| samples   | 4.36e+04 |
| step      | 340      |
------------------------
------------------------
| grad_norm | 0.172    |
| loss      | 0.0298   |
| loss_q0   | 0.0935   |
| loss_q1   | 0.00983  |
| loss_q2   | 0.00284  |
| loss_q3   | 0.00147  |
| mse       | 0.0298   |
| mse_q0    | 0.0935   |
| mse_q1    | 0.00983  |
| mse_q2    | 0.00284  |
| mse_q3    | 0.00147  |
| samples   | 4.49e+04 |
| step      | 350      |
------------------------
------------------------
| grad_norm | 0.162    |
| loss      | 0.0208   |
| loss_q0   | 0.0714   |
| loss_q1   | 0.0102   |
| loss_q2   | 0.00282  |
| loss_q3   | 0.00157  |
| mse       | 0.0208   |
| mse_q0    | 0.0714   |
| mse_q1    | 0.0102   |
| mse_q2    | 0.00282  |
| mse_q3    | 0.00157  |
| samples   | 4.62e+04 |
| step      | 360      |
------------------------
------------------------
| grad_norm | 0.153    |
| loss      | 0.0181   |
| loss_q0   | 0.0632   |
| loss_q1   | 0.00883  |
| loss_q2   | 0.00279  |
| loss_q3   | 0.00145  |
| mse       | 0.0181   |
| mse_q0    | 0.0632   |
| mse_q1    | 0.00883  |
| mse_q2    | 0.00279  |
| mse_q3    | 0.00145  |
| samples   | 4.75e+04 |
| step      | 370      |
------------------------
------------------------
| grad_norm | 0.179    |
| loss      | 0.017    |
| loss_q0   | 0.0597   |
| loss_q1   | 0.0098   |
| loss_q2   | 0.00302  |
| loss_q3   | 0.00139  |
| mse       | 0.017    |
| mse_q0    | 0.0597   |
| mse_q1    | 0.0098   |
| mse_q2    | 0.00302  |
| mse_q3    | 0.00139  |
| samples   | 4.88e+04 |
| step      | 380      |
------------------------
------------------------
| grad_norm | 0.175    |
| loss      | 0.0233   |
| loss_q0   | 0.0853   |
| loss_q1   | 0.00963  |
| loss_q2   | 0.00228  |
| loss_q3   | 0.00137  |
| mse       | 0.0233   |
| mse_q0    | 0.0853   |
| mse_q1    | 0.00963  |
| mse_q2    | 0.00228  |
| mse_q3    | 0.00137  |
| samples   | 5e+04    |
| step      | 390      |
------------------------
------------------------
| grad_norm | 0.117    |
| loss      | 0.0285   |
| loss_q0   | 0.0922   |
| loss_q1   | 0.0109   |
| loss_q2   | 0.00244  |
| loss_q3   | 0.00119  |
| mse       | 0.0285   |
| mse_q0    | 0.0922   |
| mse_q1    | 0.0109   |
| mse_q2    | 0.00244  |
| mse_q3    | 0.00119  |
| samples   | 5.13e+04 |
| step      | 400      |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.11     |
| loss      | 0.0244   |
| loss_q0   | 0.0773   |
| loss_q1   | 0.0093   |
| loss_q2   | 0.00261  |
| loss_q3   | 0.00115  |
| mse       | 0.0244   |
| mse_q0    | 0.0773   |
| mse_q1    | 0.0093   |
| mse_q2    | 0.00261  |
| mse_q3    | 0.00115  |
| samples   | 5.26e+04 |
| step      | 410      |
------------------------
------------------------
| grad_norm | 0.131    |
| loss      | 0.0268   |
| loss_q0   | 0.0997   |
| loss_q1   | 0.00992  |
| loss_q2   | 0.00276  |
| loss_q3   | 0.00118  |
| mse       | 0.0268   |
| mse_q0    | 0.0997   |
| mse_q1    | 0.00992  |
| mse_q2    | 0.00276  |
| mse_q3    | 0.00118  |
| samples   | 5.39e+04 |
| step      | 420      |
------------------------
------------------------
| grad_norm | 0.142    |
| loss      | 0.0236   |
| loss_q0   | 0.0836   |
| loss_q1   | 0.00926  |
| loss_q2   | 0.00242  |
| loss_q3   | 0.00134  |
| mse       | 0.0236   |
| mse_q0    | 0.0836   |
| mse_q1    | 0.00926  |
| mse_q2    | 0.00242  |
| mse_q3    | 0.00134  |
| samples   | 5.52e+04 |
| step      | 430      |
------------------------
------------------------
| grad_norm | 0.214    |
| loss      | 0.0164   |
| loss_q0   | 0.0622   |
| loss_q1   | 0.00966  |
| loss_q2   | 0.00276  |
| loss_q3   | 0.0014   |
| mse       | 0.0164   |
| mse_q0    | 0.0622   |
| mse_q1    | 0.00966  |
| mse_q2    | 0.00276  |
| mse_q3    | 0.0014   |
| samples   | 5.64e+04 |
| step      | 440      |
------------------------
------------------------
| grad_norm | 0.157    |
| loss      | 0.0229   |
| loss_q0   | 0.0789   |
| loss_q1   | 0.00997  |
| loss_q2   | 0.00246  |
| loss_q3   | 0.0013   |
| mse       | 0.0229   |
| mse_q0    | 0.0789   |
| mse_q1    | 0.00997  |
| mse_q2    | 0.00246  |
| mse_q3    | 0.0013   |
| samples   | 5.77e+04 |
| step      | 450      |
------------------------
------------------------
| grad_norm | 0.105    |
| loss      | 0.0272   |
| loss_q0   | 0.0884   |
| loss_q1   | 0.0101   |
| loss_q2   | 0.00229  |
| loss_q3   | 0.0013   |
| mse       | 0.0272   |
| mse_q0    | 0.0884   |
| mse_q1    | 0.0101   |
| mse_q2    | 0.00229  |
| mse_q3    | 0.0013   |
| samples   | 5.9e+04  |
| step      | 460      |
------------------------
------------------------
| grad_norm | 0.12     |
| loss      | 0.0194   |
| loss_q0   | 0.0683   |
| loss_q1   | 0.00903  |
| loss_q2   | 0.00239  |
| loss_q3   | 0.00115  |
| mse       | 0.0194   |
| mse_q0    | 0.0683   |
| mse_q1    | 0.00903  |
| mse_q2    | 0.00239  |
| mse_q3    | 0.00115  |
| samples   | 6.03e+04 |
| step      | 470      |
------------------------
------------------------
| grad_norm | 0.19     |
| loss      | 0.0264   |
| loss_q0   | 0.0992   |
| loss_q1   | 0.0109   |
| loss_q2   | 0.00266  |
| loss_q3   | 0.00128  |
| mse       | 0.0264   |
| mse_q0    | 0.0992   |
| mse_q1    | 0.0109   |
| mse_q2    | 0.00266  |
| mse_q3    | 0.00128  |
| samples   | 6.16e+04 |
| step      | 480      |
------------------------
------------------------
| grad_norm | 0.112    |
| loss      | 0.0231   |
| loss_q0   | 0.0746   |
| loss_q1   | 0.00899  |
| loss_q2   | 0.00252  |
| loss_q3   | 0.00103  |
| mse       | 0.0231   |
| mse_q0    | 0.0746   |
| mse_q1    | 0.00899  |
| mse_q2    | 0.00252  |
| mse_q3    | 0.00103  |
| samples   | 6.28e+04 |
| step      | 490      |
------------------------
------------------------
| grad_norm | 0.118    |
| loss      | 0.0201   |
| loss_q0   | 0.0681   |
| loss_q1   | 0.00987  |
| loss_q2   | 0.00233  |
| loss_q3   | 0.000999 |
| mse       | 0.0201   |
| mse_q0    | 0.0681   |
| mse_q1    | 0.00987  |
| mse_q2    | 0.00233  |
| mse_q3    | 0.000999 |
| samples   | 6.41e+04 |
| step      | 500      |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.117    |
| loss      | 0.0222   |
| loss_q0   | 0.0749   |
| loss_q1   | 0.00942  |
| loss_q2   | 0.00267  |
| loss_q3   | 0.00109  |
| mse       | 0.0222   |
| mse_q0    | 0.0749   |
| mse_q1    | 0.00942  |
| mse_q2    | 0.00267  |
| mse_q3    | 0.00109  |
| samples   | 6.54e+04 |
| step      | 510      |
------------------------
------------------------
| grad_norm | 0.11     |
| loss      | 0.0239   |
| loss_q0   | 0.0794   |
| loss_q1   | 0.00995  |
| loss_q2   | 0.00228  |
| loss_q3   | 0.000875 |
| mse       | 0.0239   |
| mse_q0    | 0.0794   |
| mse_q1    | 0.00995  |
| mse_q2    | 0.00228  |
| mse_q3    | 0.000875 |
| samples   | 6.67e+04 |
| step      | 520      |
------------------------
------------------------
| grad_norm | 0.129    |
| loss      | 0.0215   |
| loss_q0   | 0.0835   |
| loss_q1   | 0.00975  |
| loss_q2   | 0.00236  |
| loss_q3   | 0.00105  |
| mse       | 0.0215   |
| mse_q0    | 0.0835   |
| mse_q1    | 0.00975  |
| mse_q2    | 0.00236  |
| mse_q3    | 0.00105  |
| samples   | 6.8e+04  |
| step      | 530      |
------------------------
------------------------
| grad_norm | 0.139    |
| loss      | 0.0216   |
| loss_q0   | 0.0941   |
| loss_q1   | 0.0104   |
| loss_q2   | 0.00239  |
| loss_q3   | 0.000955 |
| mse       | 0.0216   |
| mse_q0    | 0.0941   |
| mse_q1    | 0.0104   |
| mse_q2    | 0.00239  |
| mse_q3    | 0.000955 |
| samples   | 6.92e+04 |
| step      | 540      |
------------------------
------------------------
| grad_norm | 0.138    |
| loss      | 0.0221   |
| loss_q0   | 0.084    |
| loss_q1   | 0.00942  |
| loss_q2   | 0.0019   |
| loss_q3   | 0.00104  |
| mse       | 0.0221   |
| mse_q0    | 0.084    |
| mse_q1    | 0.00942  |
| mse_q2    | 0.0019   |
| mse_q3    | 0.00104  |
| samples   | 7.05e+04 |
| step      | 550      |
------------------------
------------------------
| grad_norm | 0.128    |
| loss      | 0.0263   |
| loss_q0   | 0.0825   |
| loss_q1   | 0.00948  |
| loss_q2   | 0.00263  |
| loss_q3   | 0.001    |
| mse       | 0.0263   |
| mse_q0    | 0.0825   |
| mse_q1    | 0.00948  |
| mse_q2    | 0.00263  |
| mse_q3    | 0.001    |
| samples   | 7.18e+04 |
| step      | 560      |
------------------------
------------------------
| grad_norm | 0.158    |
| loss      | 0.0258   |
| loss_q0   | 0.0908   |
| loss_q1   | 0.0104   |
| loss_q2   | 0.00242  |
| loss_q3   | 0.000919 |
| mse       | 0.0258   |
| mse_q0    | 0.0908   |
| mse_q1    | 0.0104   |
| mse_q2    | 0.00242  |
| mse_q3    | 0.000919 |
| samples   | 7.31e+04 |
| step      | 570      |
------------------------
------------------------
| grad_norm | 0.16     |
| loss      | 0.0156   |
| loss_q0   | 0.0612   |
| loss_q1   | 0.00954  |
| loss_q2   | 0.00249  |
| loss_q3   | 0.00096  |
| mse       | 0.0156   |
| mse_q0    | 0.0612   |
| mse_q1    | 0.00954  |
| mse_q2    | 0.00249  |
| mse_q3    | 0.00096  |
| samples   | 7.44e+04 |
| step      | 580      |
------------------------
------------------------
| grad_norm | 0.139    |
| loss      | 0.0212   |
| loss_q0   | 0.0666   |
| loss_q1   | 0.00915  |
| loss_q2   | 0.00217  |
| loss_q3   | 0.000887 |
| mse       | 0.0212   |
| mse_q0    | 0.0666   |
| mse_q1    | 0.00915  |
| mse_q2    | 0.00217  |
| mse_q3    | 0.000887 |
| samples   | 7.56e+04 |
| step      | 590      |
------------------------
------------------------
| grad_norm | 0.111    |
| loss      | 0.0193   |
| loss_q0   | 0.0662   |
| loss_q1   | 0.00963  |
| loss_q2   | 0.00236  |
| loss_q3   | 0.00104  |
| mse       | 0.0193   |
| mse_q0    | 0.0662   |
| mse_q1    | 0.00963  |
| mse_q2    | 0.00236  |
| mse_q3    | 0.00104  |
| samples   | 7.69e+04 |
| step      | 600      |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.15     |
| loss      | 0.0251   |
| loss_q0   | 0.0841   |
| loss_q1   | 0.00874  |
| loss_q2   | 0.00241  |
| loss_q3   | 0.000991 |
| mse       | 0.0251   |
| mse_q0    | 0.0841   |
| mse_q1    | 0.00874  |
| mse_q2    | 0.00241  |
| mse_q3    | 0.000991 |
| samples   | 7.82e+04 |
| step      | 610      |
------------------------
------------------------
| grad_norm | 0.171    |
| loss      | 0.0225   |
| loss_q0   | 0.083    |
| loss_q1   | 0.00913  |
| loss_q2   | 0.0026   |
| loss_q3   | 0.00112  |
| mse       | 0.0225   |
| mse_q0    | 0.083    |
| mse_q1    | 0.00913  |
| mse_q2    | 0.0026   |
| mse_q3    | 0.00112  |
| samples   | 7.95e+04 |
| step      | 620      |
------------------------
------------------------
| grad_norm | 0.187    |
| loss      | 0.0232   |
| loss_q0   | 0.0665   |
| loss_q1   | 0.0105   |
| loss_q2   | 0.00261  |
| loss_q3   | 0.000984 |
| mse       | 0.0232   |
| mse_q0    | 0.0665   |
| mse_q1    | 0.0105   |
| mse_q2    | 0.00261  |
| mse_q3    | 0.000984 |
| samples   | 8.08e+04 |
| step      | 630      |
------------------------
------------------------
| grad_norm | 0.102    |
| loss      | 0.0199   |
| loss_q0   | 0.0659   |
| loss_q1   | 0.00919  |
| loss_q2   | 0.00225  |
| loss_q3   | 0.000908 |
| mse       | 0.0199   |
| mse_q0    | 0.0659   |
| mse_q1    | 0.00919  |
| mse_q2    | 0.00225  |
| mse_q3    | 0.000908 |
| samples   | 8.2e+04  |
| step      | 640      |
------------------------
------------------------
| grad_norm | 0.142    |
| loss      | 0.0205   |
| loss_q0   | 0.0705   |
| loss_q1   | 0.0116   |
| loss_q2   | 0.00236  |
| loss_q3   | 0.000858 |
| mse       | 0.0205   |
| mse_q0    | 0.0705   |
| mse_q1    | 0.0116   |
| mse_q2    | 0.00236  |
| mse_q3    | 0.000858 |
| samples   | 8.33e+04 |
| step      | 650      |
------------------------
------------------------
| grad_norm | 0.156    |
| loss      | 0.0199   |
| loss_q0   | 0.0671   |
| loss_q1   | 0.00912  |
| loss_q2   | 0.00264  |
| loss_q3   | 0.000865 |
| mse       | 0.0199   |
| mse_q0    | 0.0671   |
| mse_q1    | 0.00912  |
| mse_q2    | 0.00264  |
| mse_q3    | 0.000865 |
| samples   | 8.46e+04 |
| step      | 660      |
------------------------
------------------------
| grad_norm | 0.134    |
| loss      | 0.0181   |
| loss_q0   | 0.06     |
| loss_q1   | 0.00907  |
| loss_q2   | 0.0021   |
| loss_q3   | 0.000757 |
| mse       | 0.0181   |
| mse_q0    | 0.06     |
| mse_q1    | 0.00907  |
| mse_q2    | 0.0021   |
| mse_q3    | 0.000757 |
| samples   | 8.59e+04 |
| step      | 670      |
------------------------
------------------------
| grad_norm | 0.104    |
| loss      | 0.0218   |
| loss_q0   | 0.0798   |
| loss_q1   | 0.00913  |
| loss_q2   | 0.00215  |
| loss_q3   | 0.000682 |
| mse       | 0.0218   |
| mse_q0    | 0.0798   |
| mse_q1    | 0.00913  |
| mse_q2    | 0.00215  |
| mse_q3    | 0.000682 |
| samples   | 8.72e+04 |
| step      | 680      |
------------------------
------------------------
| grad_norm | 0.209    |
| loss      | 0.0174   |
| loss_q0   | 0.0576   |
| loss_q1   | 0.00916  |
| loss_q2   | 0.00223  |
| loss_q3   | 0.000874 |
| mse       | 0.0174   |
| mse_q0    | 0.0576   |
| mse_q1    | 0.00916  |
| mse_q2    | 0.00223  |
| mse_q3    | 0.000874 |
| samples   | 8.84e+04 |
| step      | 690      |
------------------------
------------------------
| grad_norm | 0.155    |
| loss      | 0.0177   |
| loss_q0   | 0.0709   |
| loss_q1   | 0.0108   |
| loss_q2   | 0.00216  |
| loss_q3   | 0.000769 |
| mse       | 0.0177   |
| mse_q0    | 0.0709   |
| mse_q1    | 0.0108   |
| mse_q2    | 0.00216  |
| mse_q3    | 0.000769 |
| samples   | 8.97e+04 |
| step      | 700      |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.119    |
| loss      | 0.025    |
| loss_q0   | 0.084    |
| loss_q1   | 0.00894  |
| loss_q2   | 0.00197  |
| loss_q3   | 0.000799 |
| mse       | 0.025    |
| mse_q0    | 0.084    |
| mse_q1    | 0.00894  |
| mse_q2    | 0.00197  |
| mse_q3    | 0.000799 |
| samples   | 9.1e+04  |
| step      | 710      |
------------------------
------------------------
| grad_norm | 0.168    |
| loss      | 0.0226   |
| loss_q0   | 0.0748   |
| loss_q1   | 0.0103   |
| loss_q2   | 0.00233  |
| loss_q3   | 0.000883 |
| mse       | 0.0226   |
| mse_q0    | 0.0748   |
| mse_q1    | 0.0103   |
| mse_q2    | 0.00233  |
| mse_q3    | 0.000883 |
| samples   | 9.23e+04 |
| step      | 720      |
------------------------
------------------------
| grad_norm | 0.197    |
| loss      | 0.0194   |
| loss_q0   | 0.066    |
| loss_q1   | 0.00939  |
| loss_q2   | 0.00229  |
| loss_q3   | 0.000856 |
| mse       | 0.0194   |
| mse_q0    | 0.066    |
| mse_q1    | 0.00939  |
| mse_q2    | 0.00229  |
| mse_q3    | 0.000856 |
| samples   | 9.36e+04 |
| step      | 730      |
------------------------
------------------------
| grad_norm | 0.149    |
| loss      | 0.02     |
| loss_q0   | 0.0691   |
| loss_q1   | 0.00907  |
| loss_q2   | 0.00199  |
| loss_q3   | 0.00088  |
| mse       | 0.02     |
| mse_q0    | 0.0691   |
| mse_q1    | 0.00907  |
| mse_q2    | 0.00199  |
| mse_q3    | 0.00088  |
| samples   | 9.48e+04 |
| step      | 740      |
------------------------
------------------------
| grad_norm | 0.137    |
| loss      | 0.0189   |
| loss_q0   | 0.0702   |
| loss_q1   | 0.00956  |
| loss_q2   | 0.00212  |
| loss_q3   | 0.000781 |
| mse       | 0.0189   |
| mse_q0    | 0.0702   |
| mse_q1    | 0.00956  |
| mse_q2    | 0.00212  |
| mse_q3    | 0.000781 |
| samples   | 9.61e+04 |
| step      | 750      |
------------------------

===================================================================================
=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES
=   PID 1623 RUNNING AT amax
=   EXIT CODE: 15
=   CLEANING UP REMAINING PROCESSES
=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES
===================================================================================
YOUR APPLICATION TERMINATED WITH THE EXIT STRING: Terminated (signal 15)
This typically refers to a problem with your application.
Please see the FAQ page for debugging suggestions
